{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98be3780-1bf5-490b-b0a2-55ad8733f3a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-16 15:31:44.774942: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BartForConditionalGeneration, BartConfig\n",
    "from transformers import Trainer, TrainingArguments, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "from preprocessing import *\n",
    "import os\n",
    "from glob import glob\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34462b98-3f1d-466f-902a-6f1009ac7063",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = Preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f82a74b4-3643-4625-a4b7-d4a9c5393f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path_list = glob('./Train/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60378bc5-8aa7-4f22-9f8c-12b6f1bd2d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_json_list = preprocess.make_dataset_list(train_path_list)\n",
    "train_data= preprocess.make_set_as_df(train_json_list)\n",
    "encoder_input_train, decoder_output_train = preprocess.make_tokenizer_input(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21764e3b-e9ac-4c06-aa4c-37217e591a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['근데 왜 막말을 할까... 이유가 뭘까... 남의 기분따위 상관없다는 그런 뉘앙스는 뭘까.. 허..빡쳐 흥분하면 감정적이여 지자나,, 이걸 잘 다스리는 사람이 진짜 멋지더라,, 근데 그걸 조절을 해야지 나이가 맣ㄴ으면 긍깨,,,', '대박 #@소속# 다니던 #@이름# 아는사람 ㅋㅋㅋ옹아로 하얀애 방금 이쁘장한애 생생정보통 나옴 ㅋㅋㅋㅋㅋ 잉 왜??? 왜?? 족발 무한리필집 나오는데 인천에 잇는거고든 걔 거기서 먹고 인터뷰함']\n",
      "[' [CLS] 집에서 밥을 해먹어야 해서 엄마 카드(엄카)를 가지고 장을 보러 간다. [SEP] ', ' [CLS] 실바니안은 코스트코에 가서 사는 것보다 인터넷으로 사는 게 더 싸다. [SEP] ']\n"
     ]
    }
   ],
   "source": [
    "print(encoder_input_train[:2])\n",
    "print(encoder_input_train[-2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb81cdb-00b2-4e3e-9a2e-d23db3fe0450",
   "metadata": {},
   "source": [
    "# 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "249ff567-60fa-4e70-ba3f-b01a9a8cd243",
   "metadata": {},
   "outputs": [],
   "source": [
    "from soynlp.normalizer import *\n",
    "#from pykospacing import Spacing\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def delete_char(texts):\n",
    "    preprocessed_text = []\n",
    "    proc = re.compile(r\"[^ㄱ-ㅎ가-힣a-zA-Z!?@#$%^&*()_ +]\")\n",
    "    for text in tqdm(texts):\n",
    "        text = proc.sub(\"\", text).strip()\n",
    "        if text:\n",
    "            preprocessed_text.append(text)\n",
    "    return preprocessed_text\n",
    "\n",
    "def spacing_sent(texts):\n",
    "    \"\"\"\n",
    "    띄어쓰기를 보정합니다.\n",
    "    \"\"\"\n",
    "    spacing = Spacing()\n",
    "    preprocessed_text = []\n",
    "    for text in tqdm(texts):\n",
    "        text = spacing(text)\n",
    "        if text:\n",
    "            preprocessed_text.append(text)\n",
    "    return preprocessed_text\n",
    "\n",
    "def remove_repeat_char(texts):\n",
    "    preprocessed_text = []\n",
    "    for text in tqdm(texts):\n",
    "        text = repeat_normalize(text, num_repeats=2).strip()\n",
    "        if text:\n",
    "            preprocessed_text.append(text)\n",
    "    return preprocessed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c532c936-29d4-4a21-ac9c-c9c1330081a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0344181a60b64794b2b4216ea8f7f3c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=232062.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43ddd8079658423fa38c46f582cf31d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=232062.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "encoder_input_train = delete_char(encoder_input_train)\n",
    "encoder_input_train = remove_repeat_char(encoder_input_train)\n",
    "#encoder_input_train = spacing_sent(encoder_input_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "853e3cc3-c7d9-4a46-848e-349d973ff376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['근데 왜 막말을 할까 이유가 뭘까 남의 기분따위 상관없다는 그런 뉘앙스는 뭘까 허빡쳐 흥분하면 감정적이여 지자나 이걸 잘 다스리는 사람이 진짜 멋지더라 근데 그걸 조절을 해야지 나이가 맣ㄴ으면 긍깨', '대박 #@소속# 다니던 #@이름# 아는사람 ㅋㅋㅋ옹아로 하얀애 방금 이쁘장한애 생생정보통 나옴 ㅋㅋ 잉 왜??? 왜?? 족발 무한리필집 나오는데 인천에 잇는거고든 걔 거기서 먹고 인터뷰함']\n",
      "['CLS 집에서 밥을 해먹어야 해서 엄마 카드(엄카)를 가지고 장을 보러 간다 SEP', 'CLS 실바니안은 코스트코에 가서 사는 것보다 인터넷으로 사는 게 더 싸다 SEP']\n"
     ]
    }
   ],
   "source": [
    "print(encoder_input_train[:2])\n",
    "print(encoder_input_train[-2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06bacbb4-5d9d-4896-8440-5066c50f132f",
   "metadata": {},
   "source": [
    "# Make Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18d8a84f-128d-44af-bd71-86963cad3feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import BertWordPieceTokenizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "304ccc7b-4c56-4367-98f6-9911df661f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_dir = './vocab/vocab_preprocessed.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30a68896-6d14-4451-99e7-cc8608c1400b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Make tokenizer and train ----------\n",
      "\n",
      "\n",
      "\n",
      "---------- Make tokenizer and train complete ----------\n"
     ]
    }
   ],
   "source": [
    "print('-'*10, 'Make tokenizer and train', '-'*10,)\n",
    "tokenizer = BertWordPieceTokenizer(\n",
    "    None,\n",
    "    clean_text=True,\n",
    "    handle_chinese_chars=True,\n",
    "    strip_accents=False, # Must be False if cased model\n",
    "    lowercase=False,\n",
    "    wordpieces_prefix=\"##\",\n",
    ")\n",
    "tokenizer.add_special_tokens([\"[PAD]\", \"[CLS]\", \"[UNK]\", \"[SEP]\", \"[MASK]\"]) #\"<pad>\", \"<s>\", \"</s>\", \"<sep>\", \"<mask>\"\n",
    "tokenizer.train_from_iterator(\n",
    "    encoder_input_train,\n",
    "    vocab_size=50000,\n",
    "    min_frequency=2,\n",
    "    show_progress=True,\n",
    "    special_tokens = [\"[PAD]\", \"[CLS]\", \"[UNK]\", \"[SEP]\", \"[MASK]\"],#\"<pad>\", \"<s>\", \"</s>\", \"<sep>\", \"<mask>\"\n",
    "    wordpieces_prefix=\"##\",\n",
    ")\n",
    "print('-'*10, 'Make tokenizer and train complete', '-'*10,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3bd72c7-042e-47e2-864c-1b360ed586db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n"
     ]
    }
   ],
   "source": [
    "vocab = tokenizer.get_vocab()\n",
    "print(len(vocab))\n",
    "\n",
    "vocabulary = [[v, k] for k, v in vocab.items()]\n",
    "vocabulary = sorted(vocabulary)\n",
    "vocabulary = list(np.array(vocabulary)[:, 1])\n",
    "\n",
    "with open(vocab_dir, 'w+') as lf:\n",
    "    lf.write('\\n'.join(vocabulary))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92bd3bc-0276-432e-8358-8163da8f233f",
   "metadata": {},
   "source": [
    "# Load Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ee72a9b2-a8c5-413b-932f-3df500139100",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0bfa4c0b-ef55-4347-a988-16dfecbf4edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Didn't find file ./vocab/added_tokens.json. We won't load it.\n",
      "Didn't find file ./vocab/special_tokens_map.json. We won't load it.\n",
      "Didn't find file ./vocab/tokenizer_config.json. We won't load it.\n",
      "Didn't find file ./vocab/tokenizer.json. We won't load it.\n",
      "loading file ./vocab/vocab.txt\n",
      "loading file None\n",
      "loading file None\n",
      "loading file None\n",
      "loading file None\n",
      "file ./vocab/config.json not found\n"
     ]
    }
   ],
   "source": [
    "bert_tokenizer = BertTokenizer.from_pretrained('./vocab/', do_basic_tokenize=False) #(vocab_file = './vocab/vocab.txt',  do_basic_tokenize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecb675d-c7e0-417c-83e8-aa4f3cd661d9",
   "metadata": {},
   "source": [
    "# Model Pretraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f0cb6241-81fe-4c37-b64a-2e8dd50f0c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BartForCausalLM, BartConfig, BartForConditionalGeneration\n",
    "from transformers.tokenization_utils import PreTrainedTokenizer\n",
    "from transformers import DataCollatorForLanguageModeling, DataCollatorForPermutationLanguageModeling\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "59e1d731-afb6-49f3-b12d-17567dd6d8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LineByLineTextDataset(Dataset):\n",
    "    \"\"\"\n",
    "    This will be superseded by a framework-agnostic approach soon.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, tokenizer: PreTrainedTokenizer, data, block_size: int):\n",
    "        batch_encoding = tokenizer(data, add_special_tokens=True, truncation=True, max_length=block_size)\n",
    "        self.examples = batch_encoding[\"input_ids\"]\n",
    "        self.examples = [{\"input_ids\": torch.tensor(e, dtype=torch.long)} for e in self.examples]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.examples[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2b3a09cf-947b-40ef-9e4e-3f5a6e73d0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = LineByLineTextDataset(\n",
    "        tokenizer=bert_tokenizer,\n",
    "        data=list(encoder_input_train),\n",
    "        block_size=256,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bd46a34f-2e0d-4265-9737-c6927247deec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set mlm task  DataCollatorForSOP(DataCollatorForLanguageModeling)\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=bert_tokenizer, mlm=True, mlm_probability=0.15\n",
    ")\n",
    "# data_collator = DataCollatorForPermutationLanguageModeling(\n",
    "#     tokenizer=bert_tokenizer, max_span_length=5, plm_probability=0.15\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1bb11b25-f547-4ea6-acdf-988da67abd7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(50000, 1024)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = BartConfig()\n",
    "config.d_model = 1024\n",
    "config.encoder_ffn_dim = 512\n",
    "config.decoder_ffn_dim = 512\n",
    "config.encoder_attention_heads = 8\n",
    "config.decoder_start_token_id = 8\n",
    "config.max_position_embeddings = 512\n",
    "config.encoder_layers = 6\n",
    "config.decoder_layers = 6\n",
    "model = BartForCausalLM(config=config)\n",
    "model.resize_token_embeddings(len(bert_tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1c11ce68-758a-49f8-9099-b8ff6f5cc7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set training args\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir='./outputs_preprocessing/',\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=15,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    gradient_accumulation_steps=10,\n",
    "    evaluation_strategy = 'epoch',\n",
    "    save_strategy = 'epoch',\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,\n",
    "    seed=42,\n",
    ")\n",
    "# set Trainer class for pre-training\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=dataset,\n",
    "    eval_dataset=dataset,    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a3220e63-a58a-46f7-91bc-bafe9f22233b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 232062\n",
      "  Num Epochs = 15\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 320\n",
      "  Gradient Accumulation steps = 10\n",
      "  Total optimization steps = 10875\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10875' max='10875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10875/10875 3:17:52, Epoch 14/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>8.941600</td>\n",
       "      <td>8.369273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>8.496500</td>\n",
       "      <td>8.241735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8.330000</td>\n",
       "      <td>8.174495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>8.299200</td>\n",
       "      <td>8.101591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>8.228400</td>\n",
       "      <td>8.054579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>8.203600</td>\n",
       "      <td>8.003556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>8.143200</td>\n",
       "      <td>7.945886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>8.109300</td>\n",
       "      <td>7.886611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>8.039200</td>\n",
       "      <td>7.834373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>8.015800</td>\n",
       "      <td>7.803403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>7.991000</td>\n",
       "      <td>7.763926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>7.948800</td>\n",
       "      <td>7.737667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>7.936800</td>\n",
       "      <td>7.720667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>7.905500</td>\n",
       "      <td>7.709297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>7.912100</td>\n",
       "      <td>7.700473</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 232062\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./outputs_SOP/checkpoint-725\n",
      "Configuration saved in ./outputs_SOP/checkpoint-725/config.json\n",
      "Model weights saved in ./outputs_SOP/checkpoint-725/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 232062\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./outputs_SOP/checkpoint-1450\n",
      "Configuration saved in ./outputs_SOP/checkpoint-1450/config.json\n",
      "Model weights saved in ./outputs_SOP/checkpoint-1450/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 232062\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./outputs_SOP/checkpoint-2175\n",
      "Configuration saved in ./outputs_SOP/checkpoint-2175/config.json\n",
      "Model weights saved in ./outputs_SOP/checkpoint-2175/pytorch_model.bin\n",
      "Deleting older checkpoint [outputs_SOP/checkpoint-725] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 232062\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./outputs_SOP/checkpoint-2900\n",
      "Configuration saved in ./outputs_SOP/checkpoint-2900/config.json\n",
      "Model weights saved in ./outputs_SOP/checkpoint-2900/pytorch_model.bin\n",
      "Deleting older checkpoint [outputs_SOP/checkpoint-1450] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 232062\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./outputs_SOP/checkpoint-3625\n",
      "Configuration saved in ./outputs_SOP/checkpoint-3625/config.json\n",
      "Model weights saved in ./outputs_SOP/checkpoint-3625/pytorch_model.bin\n",
      "Deleting older checkpoint [outputs_SOP/checkpoint-2175] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 232062\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./outputs_SOP/checkpoint-4350\n",
      "Configuration saved in ./outputs_SOP/checkpoint-4350/config.json\n",
      "Model weights saved in ./outputs_SOP/checkpoint-4350/pytorch_model.bin\n",
      "Deleting older checkpoint [outputs_SOP/checkpoint-2900] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 232062\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./outputs_SOP/checkpoint-5075\n",
      "Configuration saved in ./outputs_SOP/checkpoint-5075/config.json\n",
      "Model weights saved in ./outputs_SOP/checkpoint-5075/pytorch_model.bin\n",
      "Deleting older checkpoint [outputs_SOP/checkpoint-3625] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 232062\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./outputs_SOP/checkpoint-5800\n",
      "Configuration saved in ./outputs_SOP/checkpoint-5800/config.json\n",
      "Model weights saved in ./outputs_SOP/checkpoint-5800/pytorch_model.bin\n",
      "Deleting older checkpoint [outputs_SOP/checkpoint-4350] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 232062\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./outputs_SOP/checkpoint-6525\n",
      "Configuration saved in ./outputs_SOP/checkpoint-6525/config.json\n",
      "Model weights saved in ./outputs_SOP/checkpoint-6525/pytorch_model.bin\n",
      "Deleting older checkpoint [outputs_SOP/checkpoint-5075] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 232062\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./outputs_SOP/checkpoint-7250\n",
      "Configuration saved in ./outputs_SOP/checkpoint-7250/config.json\n",
      "Model weights saved in ./outputs_SOP/checkpoint-7250/pytorch_model.bin\n",
      "Deleting older checkpoint [outputs_SOP/checkpoint-5800] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 232062\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./outputs_SOP/checkpoint-7975\n",
      "Configuration saved in ./outputs_SOP/checkpoint-7975/config.json\n",
      "Model weights saved in ./outputs_SOP/checkpoint-7975/pytorch_model.bin\n",
      "Deleting older checkpoint [outputs_SOP/checkpoint-6525] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 232062\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./outputs_SOP/checkpoint-8700\n",
      "Configuration saved in ./outputs_SOP/checkpoint-8700/config.json\n",
      "Model weights saved in ./outputs_SOP/checkpoint-8700/pytorch_model.bin\n",
      "Deleting older checkpoint [outputs_SOP/checkpoint-7250] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 232062\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./outputs_SOP/checkpoint-9425\n",
      "Configuration saved in ./outputs_SOP/checkpoint-9425/config.json\n",
      "Model weights saved in ./outputs_SOP/checkpoint-9425/pytorch_model.bin\n",
      "Deleting older checkpoint [outputs_SOP/checkpoint-7975] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 232062\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./outputs_SOP/checkpoint-10150\n",
      "Configuration saved in ./outputs_SOP/checkpoint-10150/config.json\n",
      "Model weights saved in ./outputs_SOP/checkpoint-10150/pytorch_model.bin\n",
      "Deleting older checkpoint [outputs_SOP/checkpoint-8700] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 232062\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./outputs_SOP/checkpoint-10875\n",
      "Configuration saved in ./outputs_SOP/checkpoint-10875/config.json\n",
      "Model weights saved in ./outputs_SOP/checkpoint-10875/pytorch_model.bin\n",
      "Deleting older checkpoint [outputs_SOP/checkpoint-9425] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./outputs_SOP/checkpoint-10875 (score: 7.700472831726074).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=10875, training_loss=8.147608117816091, metrics={'train_runtime': 11873.9712, 'train_samples_per_second': 293.156, 'train_steps_per_second': 0.916, 'total_flos': 2.6954582842773504e+16, 'train_loss': 8.147608117816091, 'epoch': 15.0})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5c2754-30f9-4e0b-8975-fbc2867f2a4c",
   "metadata": {},
   "source": [
    "# Model fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "74bd1c9b-c3c1-43ed-b3f4-c8247dfe7a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_ids=None,\n",
    "# attention_mask=None,\n",
    "# decoder_input_ids=None,\n",
    "# decoder_attention_mask=None,\n",
    "# labels=None,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "20a28c3a-b20b-4fc2-bfd7-045916de4f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mydataset(Dataset):\n",
    "    def __init__(self, encoder_input, decoder_input, labels, len):\n",
    "        self.encoder_input = encoder_input\n",
    "        self.decoder_input = decoder_input\n",
    "        self.labels = labels\n",
    "        self.len = len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx].clone().detach() for key, val in self.encoder_input.items()}\n",
    "        item2 = {key: val[idx].clone().detach() for key, val in self.decoder_input.items()}\n",
    "        item2['decoder_input_ids'] = item2['input_ids']\n",
    "        item2['decoder_attention_mask'] = item2['attention_mask']\n",
    "        item2.pop('input_ids')\n",
    "        item2.pop('attention_mask')\n",
    "        item.update(item2)\n",
    "        item['labels'] = self.labels['input_ids'][idx]\n",
    "        return item\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8da23644-4cde-40a4-be58-72d12b9178b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d3a3e1ed-348a-49bb-b19e-2995a8cf441f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_list = glob('./outputs_SOP/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "24fc77f5-2d99-4a9b-9580-39298fa5b4e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(50000, 1024)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = BartConfig()\n",
    "config.d_model = 1024\n",
    "config.encoder_ffn_dim = 512\n",
    "config.decoder_ffn_dim = 512\n",
    "config.encoder_attention_heads = 8\n",
    "config.decoder_start_token_id = 8\n",
    "config.max_position_embeddings = 512\n",
    "config.encoder_layers = 6\n",
    "config.decoder_layers = 6\n",
    "generate_model = BartForConditionalGeneration(config=config)\n",
    "generate_model.resize_token_embeddings(len(bert_tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "31e093d3-dd75-40ac-b2d7-8f6e8f01b495",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_train, decoder_input_train, decoder_output_train = preprocess.make_model_input(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a9cfbffc-8719-468a-a540-7dfc09e31349",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_encoder_inputs = bert_tokenizer(list(encoder_input_train), return_tensors=\"pt\", padding=True, \n",
    "                            add_special_tokens=True, truncation=True, max_length=256, return_token_type_ids=False,)\n",
    "tokenized_decoder_inputs = bert_tokenizer(list(decoder_input_train), return_tensors=\"pt\", padding=True, \n",
    "                            add_special_tokens=True, truncation=True, max_length=50, return_token_type_ids=False,)\n",
    "tokenized_decoder_ouputs = bert_tokenizer(list(decoder_output_train), return_tensors=\"pt\", padding=True, \n",
    "                            add_special_tokens=True, truncation=True, max_length=50, return_token_type_ids=False,)\n",
    "\n",
    "encoder_inputs_dataset = Mydataset(tokenized_encoder_inputs, tokenized_decoder_inputs, tokenized_decoder_ouputs, len(encoder_input_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c9bbc174-87f1-435a-bd37-acd5b8b72332",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "# set training args\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir='./bart_prerprocess_without_pretraining_v3/',\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=50,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    gradient_accumulation_steps=10,\n",
    "    evaluation_strategy = 'epoch',\n",
    "    save_strategy = 'epoch',\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,\n",
    "    seed=42,\n",
    ")\n",
    "# set Trainer class for pre-training\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=generate_model,\n",
    "    args=training_args,\n",
    "    train_dataset=encoder_inputs_dataset,\n",
    "    eval_dataset=encoder_inputs_dataset,    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422964fe-4e68-4543-a391-48e8c7ae14d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 116031\n",
      "  Num Epochs = 50\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 320\n",
      "  Gradient Accumulation steps = 10\n",
      "  Total optimization steps = 18100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1811' max='18100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 1811/18100 2:09:59 < 19:30:30, 0.23 it/s, Epoch 5.00/50]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.883409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.036200</td>\n",
       "      <td>1.673305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.703800</td>\n",
       "      <td>1.505078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.703800</td>\n",
       "      <td>1.380668</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1195' max='3626' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1195/3626 02:17 < 04:40, 8.65 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 116031\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./bart_prerprocess_without_pretraining_v3/checkpoint-362\n",
      "Configuration saved in ./bart_prerprocess_without_pretraining_v3/checkpoint-362/config.json\n",
      "Model weights saved in ./bart_prerprocess_without_pretraining_v3/checkpoint-362/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 116031\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./bart_prerprocess_without_pretraining_v3/checkpoint-724\n",
      "Configuration saved in ./bart_prerprocess_without_pretraining_v3/checkpoint-724/config.json\n",
      "Model weights saved in ./bart_prerprocess_without_pretraining_v3/checkpoint-724/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 116031\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./bart_prerprocess_without_pretraining_v3/checkpoint-1086\n",
      "Configuration saved in ./bart_prerprocess_without_pretraining_v3/checkpoint-1086/config.json\n",
      "Model weights saved in ./bart_prerprocess_without_pretraining_v3/checkpoint-1086/pytorch_model.bin\n",
      "Deleting older checkpoint [bart_prerprocess_without_pretraining_v3/checkpoint-362] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 116031\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./bart_prerprocess_without_pretraining_v3/checkpoint-1448\n",
      "Configuration saved in ./bart_prerprocess_without_pretraining_v3/checkpoint-1448/config.json\n",
      "Model weights saved in ./bart_prerprocess_without_pretraining_v3/checkpoint-1448/pytorch_model.bin\n",
      "Deleting older checkpoint [bart_prerprocess_without_pretraining_v3/checkpoint-724] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 116031\n",
      "  Batch size = 32\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09779114-44c0-4a25-a1f0-d4935927254e",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ad61122-e561-475b-bcd2-1fbabbdaa724",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BartForConditionalGeneration, BartConfig\n",
    "from transformers import Trainer, TrainingArguments, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "from preprocessing import *\n",
    "import os\n",
    "from glob import glob\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1219191d-7a07-4a79-888b-38c059e2414e",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = Preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "caaa739d-8d19-4ed1-94db-8cd1744ae052",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ./bart_prerprocess_without_pretraining_v2/checkpoint-18100/config.json\n",
      "Model config BartConfig {\n",
      "  \"_name_or_path\": \"./bart_prerprocess_without_pretraining/checkpoint-7240/\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"BartForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 512,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 8,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 8,\n",
      "  \"encoder_ffn_dim\": 512,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.11.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50000\n",
      "}\n",
      "\n",
      "loading weights file ./bart_prerprocess_without_pretraining_v2/checkpoint-18100/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BartForConditionalGeneration.\n",
      "\n",
      "All the weights of BartForConditionalGeneration were initialized from the model checkpoint at ./bart_prerprocess_without_pretraining_v2/checkpoint-18100/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BartForConditionalGeneration for predictions without further training.\n",
      "Didn't find file ./vocab/added_tokens.json. We won't load it.\n",
      "Didn't find file ./vocab/special_tokens_map.json. We won't load it.\n",
      "Didn't find file ./vocab/tokenizer_config.json. We won't load it.\n",
      "Didn't find file ./vocab/tokenizer.json. We won't load it.\n",
      "loading file ./vocab/vocab.txt\n",
      "loading file None\n",
      "loading file None\n",
      "loading file None\n",
      "loading file None\n",
      "file ./vocab/config.json not found\n"
     ]
    }
   ],
   "source": [
    "generate_model = BartForConditionalGeneration.from_pretrained('./bart_prerprocess_without_pretraining_v2/checkpoint-18100/').to('cuda:0')\n",
    "bert_tokenizer = BertTokenizer.from_pretrained('./vocab/', do_basic_tokenize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fa0d7d4d-1794-43fb-993a-9c3ac10db4eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_json_path :\n",
      "./Valid/미용과건강.json\n",
      "test_path_list :\n",
      "['./Valid/미용과건강.json']\n",
      "test_data:\n",
      "0       따뜻하게 자라 요새 목은 좀 괜찮아 졌나 엉 괜찮아 수업을안하니까 엉 목에 수건감고...\n",
      "1       머리 뽀글뽀글 말아? 머리위에만 옆은 보통 알아서 해준데 알아서 잘 해주겠지ㅎㅎ 남...\n",
      "2       갑자기 엉뽕 #@기타# 극단 ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ 아니 엄마가 엉덩이 이야...\n",
      "3       우리 식습관 고치자 진ㅉ 맵고 짠거 스탑 머리론 알겟다고 ㅋㅋㅋㅋㅋㅋㅋㅋㅋ 실천이 ...\n",
      "4       일단..검사결과나올때까진 숨길라했는데 망쳤네 안돼ㅜㅜㅜ 내가알아야지ㅜㅡㅠㅜ 진짜가면...\n",
      "                              ...                        \n",
      "2054    병원 간겨?? 웅웅 조금 전에 막 도착. 붕대감은 거랑 테이프 떼었는데... 아직 ...\n",
      "2055    ㅋㅋㅋㅋ허리는 많이 좋아졌어?? 웅! 막 예전엔 허리아팠는데 지금은 허리좀아픈애 좀...\n",
      "2056    방금 엄마 스쿼트 알려드리고 왔어 갑자기 아빠가 체성분체중계가 있다고 꺼내오셨는데 ...\n",
      "2057    그렇죠 특히나 기관지에 예민하신 분들은 맞아요 너무 힘들어 하시더라고요 저희 사장님...\n",
      "2058    아 나 파마한거 다 풀림;; 왼쪽 거의다 풀림 짜증낰ㅋㅋㅋ 헉 미친 벌써..? 사진...\n",
      "Name: dialogue, Length: 2059, dtype: object\n"
     ]
    }
   ],
   "source": [
    "test_json_path = './Valid/미용과건강.json'\n",
    "test_path_list = glob(test_json_path)\n",
    "test_path_list.sort()\n",
    "\n",
    "test_json_list = preprocess.make_dataset_list(test_path_list)\n",
    "test_data = preprocess.make_set_as_df(test_json_list)\n",
    "\n",
    "encoder_input_test, decoder_input_test = preprocess.make_model_input(test_data, is_test= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e5b7b0aa-2750-4072-8bb8-d939d67e03df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d2f22a99da44406a90fa099009b0ee4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2059.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d833222042840828317ce80ca53499d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2059.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "encoder_input_test = delete_char(encoder_input_test)\n",
    "encoder_input_test = remove_repeat_char(encoder_input_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0fb36d-ef63-42fe-9b54-670cc88a82c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(encoder_input_test[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f02b2660-c80f-4031-b9c6-5ce012f9439d",
   "metadata": {},
   "outputs": [],
   "source": [
    "si = 0\n",
    "ei = 20\n",
    "tokenized_encoder_inputs = bert_tokenizer(list(encoder_input_test[si:ei]), return_tensors=\"pt\", padding=True, add_special_tokens=True, truncation=True, max_length=256, return_token_type_ids=False,)\n",
    "with torch.no_grad():\n",
    "    generated_ids = generate_model.generate(input_ids=tokenized_encoder_inputs['input_ids'].to('cuda:0'), max_length=100, num_beams=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "50cfb851-139c-4564-900c-acb7946d7957",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = [bert_tokenizer.decode(g_ids, skip_special_tokens=True) for g_ids in generated_ids.cpu().numpy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6ef672-071c-417f-b0f4-9dedfd10a3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = [bert_tokenizer.decode(g_ids) for g_ids in tokenized_encoder_inputs['input_ids']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8cbae6c6-d27f-4f26-a8d7-4e82fa8d7d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "D:\t 따뜻하게 자라 요새 목은 좀 괜찮아 졌나 엉 괜찮아 수업을안하니까 엉 목에 수건감고자 젖은 수건 널어놔 알겠어 요샌느 별러 안건조해\n",
      "S:\t '\n",
      "gt:\t 목이 건조하면 수건을 감고 자거나 젖은 수건을 널어놓으라고 한다.\n",
      "--------------------\n",
      "--------------------\n",
      "D:\t 머리 뽀글뽀글 말아? 머리위에만 옆은 보통 알아서 해준데 알아서 잘 해주겠지ㅎㅎ 남자가 해줘? 예쁜게해준데 응응ㅎㅎ 어 부원장 예쁘게 하고 와ㅎ 다하고 사진 찍어봐봐ㅎㅎ 영양제 미리바르고 해준다고 하더데\n",
      "S:\t ' 머리 안\n",
      "gt:\t 머리를 어떤 스타일로 하는지 물어보고 예쁘게 하고 다 하고 사진 찍어 보내라고 한다.\n",
      "--------------------\n",
      "--------------------\n",
      "D:\t 갑자기 엉뽕 #@기타# 극단 ㅋㅋ 아니 엄마가 엉덩이 이야기햇어 엉덩이납닥하면 건강에도 안좋다 어쩌고저쩌고 옷입을때 어쩌고저쩌고 근데진짜 나 치마입으면 엉덩이 티 개많이나거둥 근데 엉뽕 ㅈㄹ티나고 좀 더 뚱뚱해보일거같애 차라리 플레어?치마 입는게 나을즛 금욜에 너 궁디봐여지 달라붙는거 아니면 티 안났던듯?? 금욜애 한번 봐보자 우리 옛날에 중딩때 가슴커보일라고 일부애들 가슴에 휴지넣고 양말넣은거 생각난다 ㅋㅋ나도 기억나\n",
      "S:\t ' 엄마가 일이 너무 안 맞아서 살 것이 안 맞아서 옷 입으면\n",
      "gt:\t 엄마가 엉덩이가 납작하면 건강에도 좋지 않고 옷 입을 때도 예쁘지 않다고 말씀하셨으며 스스로도 치마를 입으면 엉덩이가 납작한 게 너무 티 나서 엉덩이 뽕(엉뽕)에 대해 이야기하고 있다.\n",
      "--------------------\n",
      "--------------------\n",
      "D:\t 우리 식습관 고치자 진ㅉ 맵고 짠거 스탑 머리론 알겟다고 ㅋㅋ 실천이 안돼서 그렇다니깐 그래도 무섭자나 영영 이러케 먹고 살 순 없어 새해부터 시작하자 올바른 식습관 만들기 프로젝트 ㅋㅋㅋ 진짜 맘 먹고 해보자 살도 빠지고 좋지 오케이 가즈아\n",
      "S:\t ' 식습관이 먹고\n",
      "gt:\t 이렇게 먹고 살 수는 없으니 새해부터는 올바른 식습관 만들기 프로젝트를 하자고 한다.\n",
      "--------------------\n",
      "--------------------\n",
      "D:\t 일단검사결과나올때까진 숨길라했는데 망쳤네 안돼 내가알아야지 진짜가면한대맞을줄알아 아무일없을거야 음그래야지 내가들은병은아닐꺼야 웅!!!!그냥물혹같은거일거야 그래야해 웅그럴거야!!!!! 너무걱정마 웅걱정안할라공 그니까여보도걱정하지마\n",
      "S:\t ' 검사 후 나올\n",
      "gt:\t 검사 결과 나올 때까지 숨기려고 했던 사람에게 자신이 알아야 한다고 아무 일 없을 거고 물혹일 것이라고 말한다.\n",
      "--------------------\n",
      "--------------------\n",
      "D:\t 클렌징워터 중에서 언니는 아직도 바이오더마 센시비오를 넘는 제품은 없었어ㅋㅋ 말해서 뭐해ㅋㅋ키 나도 다양한 클렌징 워터를 써봤지만 바이오더마가 짱이지!!! 정말 군더더기없이 깔끔한 클렌징워터 같아 조금 건조해지긴 하지만! 세정력도 좋고 잔여감도 없고ㅎㅎㅎ 그럴 일은 없겠지만서두 이 제품이 단종되면 진짜 슬플거야!\n",
      "S:\t ' 클렌징 워터 중에서 갑자기 클렌징 워터 안\n",
      "gt:\t 클렌징 워터 중에는 바이오더마가 제일 좋다고 하고 단종이 되면 슬플 것이라고 한다.\n",
      "--------------------\n",
      "--------------------\n",
      "D:\t #@기타# 삼일에 한번식 다이어트 시작 수준 ㅋㅋ#@기타# 내 기준 하루 먹는거 괜찮 운덩으로 되돌릴슌잇는데 이틀이상 처먹는다 그럼 다시시작임 ㅋㅋ시자 이틀이 뭐 어때서욧 이틀도 바주라구 이틀이상은 운동으로 극복 힘들어 연달아서 운동못함 하루에 사이클 세시간이라니^^ 그걸 이틀연속으로?\n",
      "S:\t ' 3일\n",
      "gt:\t 하루 먹는 거는 괜찮은데 이틀 이상 먹으면 운동으로 극복하기 힘들어서 다시 시작해야 한다.\n",
      "--------------------\n",
      "--------------------\n",
      "D:\t #@시스템#사진# 머리이렇게할까 ? 매직 고고 ? 이건 매직 아닌데여 매직인뎅 끝에만 c컬 ㄴㄴ매직말고 파마해 왜 ? 매직은 별루야 ? ㅇㅇ 저머리 언니랑 안어울려\n",
      "S:\t ' 머리가 안\n",
      "gt:\t 언니에게 매직은 안 어울려서 파마를 하라고 한다.\n",
      "--------------------\n",
      "--------------------\n",
      "D:\t 하 왤케 어금니가 아프지 무서어 흑 썩엇나 ㅋㅋ충치? 나도오른쪽어떤이가 몰라 시려오더라 가봐야하나하 신경치료 한걸텐데 신경치료한건데 아프면이상한건데ㅋㅋ 물머글때 시려 그럼가봐야겠는데? 근접치아인건아닐까? 가봐야겟어\n",
      "S:\t ' 눈\n",
      "gt:\t 신경치료를 한 어금니가 아프고 물먹을 때 시려서 치과에 가봐야겠다.\n",
      "--------------------\n",
      "--------------------\n",
      "D:\t 이제우리 그만할때가 됏어 살을빼자 갑자기?ㅋ 나오즘 디톡스 다이어트중이양 난 저염식다이어트 젤 의미잇는 다여트네 ㅋㅋ\n",
      "S:\t ' 안\n",
      "gt:\t 요즘 디톡스 다이어트와 저염식 다이어트를 하고 있다.\n",
      "--------------------\n",
      "--------------------\n",
      "D:\t #@시스템#사진# 귀엽지 내 발가락 매니큐어 발랐다! 발가락 진짜 귀엽네 ㅋㅋ 분홍색 매니큐어 어디서 났어 나도 발라줘 우리집에 오면 발라주지 오 진짜? 나 놀러간다? 매니큐어 준비해둬!!\n",
      "S:\t ' 발가락 매니큐어\n",
      "gt:\t 발가락에 바른 분홍색 매니큐어를 보여 줬더니 이쁘다고 하면서 분홍색 매니큐어를 바르러 온다고 한다.\n",
      "--------------------\n",
      "--------------------\n",
      "D:\t 너 윤활낭염이라해 파꿈치 아프다고 제가 몸이 후돌돌 근데 나 아까 타자 완죤 빨뤠 쳤눈뎀 술강요해?보통?\n",
      "S:\t '\n",
      "gt:\t 윤활낭염이라 팔꿈치가 아프다고 말하라고 한다.\n",
      "--------------------\n",
      "--------------------\n",
      "D:\t 나 오늘 퇴근하고 올만에 런데이 해볼라구 오옷!!! 오랜만이구만 무릎 이제 괜찮나보오 웅 호주에서 사온 관절약이 있었는데 그거 꾸준히 먹었더니 뚝뚝 소리도 안나고 괜찮아진듯 그래도 무리하지 않고 뛰려고 오옷 좋구만 팟팅팟팅!! 얍얍 러닝러닝\n",
      "S:\t ' 퇴근하고 오랜만에 오랜만에 오랜만에 살\n",
      "gt:\t 오늘 퇴근하고 오랜만에 달리기를 하려고 한다.\n",
      "--------------------\n",
      "--------------------\n",
      "D:\t 순산중 으 부럽 나도 싸고싶다 화장실 찾기 드럽게 어려워 안마렵? 참아서 #@주소#서 싸 지금은 방광만 아퍼 짲응\n",
      "S:\t ' 순\n",
      "gt:\t 용변을 보고 싶은데 화장실을 못 찾아서 참고 있다.\n",
      "--------------------\n",
      "--------------------\n",
      "D:\t 나도 하나 있는데 아직 작지만 아팠댔어 마취가 여름엔하지말래서 #@이모티콘# 이런이구만 작을때가서치료받아라ㅋ나처럼키우지말고ㅋ 무섭ㅋ 작을땐 치료가 되는겨? 아 나도 조만간 함 가봐야나\n",
      "S:\t ' 또 안\n",
      "gt:\t 자신처럼 키우지 말고 작을 때 가서 치료를 받으라고 이야기한다.\n",
      "--------------------\n",
      "--------------------\n",
      "D:\t 나 사진찍힌거 보고 충격받고 이대로 라오스 갈수 없다 이상태거든? 밥은 먹지 말자 친구야 우리가 뭐 언젠 먹었냐만은 ㅋㅋ 안주 맛없는대로 가지 않을래? 의 의미엿음 술만 마시겠다?ㅋㅋ ㅇㅇ 나도 요새 살 너무 쪄서 죽겠당 그럼 어딜 가야하나 ㅋㅋ엄글게 건대냐? 왜 자꾸 맛집만 생각 나 나? #@시스템#사진# 이런 상태?ㅋㅋ 어제 웹툰보다 존 웃겨서 저장했눈뎈ㅋㅋ 그냥 바에 가야하나?ㅋㅋ 아앀ㅋㅋ미친ㅋㅋ아니 우리 핑거푸드라거나 뭐 그런거 있긴 있는데 가자맘이 바뀜\n",
      "S:\t ' 사진 보러 갈\n",
      "gt:\t 살이 너무 쪄서 안주는 먹지 말고 술만 마시자며 어디로 갈지 정한다.\n",
      "--------------------\n",
      "--------------------\n",
      "D:\t 큰일이야 나 감기 지독허게 걸렷나바 따뜻한물 마셔줘 생강차 이런거 왜캐 눈알이 아플까 건조한거 아냐?? 그런가 일정 시간만되면 춥고 머리가 아픈데 왜 그런지 모르겟어\n",
      "S:\t ' 감기\n",
      "gt:\t 일정 시간만 되면 춥고 머리가 아픈데 왜 그런지 모르겠다면서 감기가 지독하게 걸린 거 같다고 하니 따뜻한 물이나 생강차를 권한다.\n",
      "--------------------\n",
      "--------------------\n",
      "D:\t 내가 흰색은 넘 고민인디 화사해보이긴 할거같은데 약간 부해보일까봐 흰색은 그냥 부 게다가 흰색 래쉬가드는 이너 수영복도 다 비친다꽆ㅍㅍ Boo 이너수영복 마따 그것도 신경써야되겠네 로켓가슴된다고 자칫 힝 의도치않은 시스루\n",
      "S:\t ' 색\n",
      "gt:\t 흰색은 화사해 보이지만 부해 보이고 비쳐서 신경 써야 된다.\n",
      "--------------------\n",
      "--------------------\n",
      "D:\t 미열있더러 사람 개많아 추위에 떨다가 이제 주사맞고 약국와써 웅 그랬꾸나 잘했오 잘했오 주사 그래도 맞아버리면 금방 나으니깐 ? 확실합니까? 아직도 코맹맹이 님? ㅋㅋ 앜ㅋㅋ 웅 금방 나을꼬야\n",
      "S:\t ' 갑자기 주사를 맞고\n",
      "gt:\t 사람 많아서 추위에 떨다가 이제 주사 맞고 약국에 왔다.\n",
      "--------------------\n",
      "--------------------\n",
      "D:\t 지금 할아버지도 나가신다 호엥 위험할거같아서 어디가셔 일단은 할머니집 그래두대? 할아버지도 격리대상자 아니셔? 근데 아빠가 더 위험하니까 할아버지 연세가 많으셔서\n",
      "S:\t ' 할아버지 안\n",
      "gt:\t 할아버지 연세가 많으셔서 할머니 집으로 가시기로 하셨다.\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "for d, tk, s, gt in zip(encoder_input_test[si:ei], tokenized, summary, test_data[\"summary\"][si:ei]):\n",
    "    print('-'*20)\n",
    "    print('D:\\t', d)\n",
    "    print('TK:\\t', tk)\n",
    "    print('S:\\t', s)\n",
    "    print('gt:\\t', gt)\n",
    "    print('-'*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4995d9-7802-4a85-b21f-bcff7c3e904d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04dfde69-0244-4f95-8337-b187ef195058",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcb717c-7653-4fe9-9c6b-53b8bd5a7134",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5fd5f4-4931-4ab2-a13c-59c0aa9835a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e34ab7-3d58-49a8-8a6f-f6d81701ec49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7a79135a-743d-41e5-9ee7-b13147ebf82a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "그리고 회사단톡 주말이건 저녁이건 계속 오는데 아니 왜 업무외시간에 그런대 먹는거 사진 올라옴 족발 찍어올리고 배고파짐 일상을 공유하고 난리야 먹방 동아리 같아\n",
      "['그리고', '회사', '##단톡', '주말이', '##건', '저녁이', '##건', '계속', '오는데', '아니', '왜', '업무', '##외', '##시간에', '그런대', '먹는거', '사진', '올라옴', '족발', '찍어', '##올리고', '배고파', '##짐', '일상을', '공유하고', '난리야', '먹방', '동아리', '같아']\n",
      "[1, 2325, 2385, 19550, 15296, 1088, 26846, 1088, 2122, 6204, 1998, 672, 9773, 1245, 4089, 33576, 5310, 2001, 20603, 9721, 3097, 23423, 3223, 1654, 33231, 10876, 13291, 14106, 10887, 2284, 3]\n",
      "[2325, 2385, 19550, 15296, 1088, 26846, 1088, 2122, 6204, 1998, 672, 9773, 1245, 4089, 33576, 5310, 2001, 20603, 9721, 3097, 23423, 3223, 1654, 33231, 10876, 13291, 14106, 10887, 2284]\n",
      "['그리고', '회사', '##단톡', '주말이', '##건', '저녁이', '##건', '계속', '오는데', '아니', '왜', '업무', '##외', '##시간에', '그런대', '먹는거', '사진', '올라옴', '족발', '찍어', '##올리고', '배고파', '##짐', '일상을', '공유하고', '난리야', '먹방', '동아리', '같아']\n"
     ]
    }
   ],
   "source": [
    "# TEST\n",
    "index = 25\n",
    "print(encoder_input_train[index])\n",
    "print(bert_tokenizer.tokenize(encoder_input_train[index]))\n",
    "print(bert_tokenizer.encode(encoder_input_train[index]))\n",
    "\n",
    "ids = tokenizer.encode(encoder_input_train[index]).ids\n",
    "print(ids)\n",
    "a = [tokenizer.id_to_token(i) for i in ids]\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a8b591-24f0-40e5-af41-6df0d81c7067",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
